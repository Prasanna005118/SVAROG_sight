{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4glK9WcFakv",
        "outputId": "25366ba6-63a0-45ee-a613-64cf3de61aa2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.3592 - loss: 1.9634 - val_accuracy: 0.5269 - val_loss: 1.1521 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.4460 - loss: 1.4658 - val_accuracy: 0.5269 - val_loss: 1.1973 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.4887 - loss: 1.3270 - val_accuracy: 0.5269 - val_loss: 1.2244 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m237/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5224 - loss: 1.2723\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5224 - loss: 1.2722 - val_accuracy: 0.5269 - val_loss: 1.1968 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.5424 - loss: 1.2354 - val_accuracy: 0.5269 - val_loss: 1.1677 - learning_rate: 5.0000e-04\n",
            "Epoch 6/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.5630 - loss: 1.1888 - val_accuracy: 0.5578 - val_loss: 1.0986 - learning_rate: 5.0000e-04\n",
            "Epoch 7/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.5972 - loss: 1.1234 - val_accuracy: 0.7444 - val_loss: 0.9748 - learning_rate: 5.0000e-04\n",
            "Epoch 8/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.6273 - loss: 1.0610 - val_accuracy: 0.7580 - val_loss: 0.8516 - learning_rate: 5.0000e-04\n",
            "Epoch 9/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.6625 - loss: 0.9815 - val_accuracy: 0.7585 - val_loss: 0.7718 - learning_rate: 5.0000e-04\n",
            "Epoch 10/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.6909 - loss: 0.9091 - val_accuracy: 0.7700 - val_loss: 0.7057 - learning_rate: 5.0000e-04\n",
            "Epoch 11/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.7136 - loss: 0.8399 - val_accuracy: 0.7831 - val_loss: 0.6683 - learning_rate: 5.0000e-04\n",
            "Epoch 12/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7395 - loss: 0.7858 - val_accuracy: 0.8076 - val_loss: 0.6452 - learning_rate: 5.0000e-04\n",
            "Epoch 13/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7446 - loss: 0.7711 - val_accuracy: 0.7872 - val_loss: 0.6275 - learning_rate: 5.0000e-04\n",
            "Epoch 14/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7574 - loss: 0.7290 - val_accuracy: 0.8050 - val_loss: 0.6152 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.7784 - loss: 0.6850 - val_accuracy: 0.8207 - val_loss: 0.5970 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7780 - loss: 0.6873 - val_accuracy: 0.8228 - val_loss: 0.5979 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7843 - loss: 0.6509 - val_accuracy: 0.8505 - val_loss: 0.5757 - learning_rate: 5.0000e-04\n",
            "Epoch 18/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.8055 - loss: 0.6270 - val_accuracy: 0.8594 - val_loss: 0.5618 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8116 - loss: 0.6198 - val_accuracy: 0.8735 - val_loss: 0.5450 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8282 - loss: 0.5942 - val_accuracy: 0.8735 - val_loss: 0.5365 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8400 - loss: 0.5707 - val_accuracy: 0.8761 - val_loss: 0.5163 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - accuracy: 0.8560 - loss: 0.5494 - val_accuracy: 0.8777 - val_loss: 0.5030 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8595 - loss: 0.5391 - val_accuracy: 0.8536 - val_loss: 0.4928 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.8709 - loss: 0.5162 - val_accuracy: 0.8411 - val_loss: 0.4935 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.8869 - loss: 0.4782 - val_accuracy: 0.8327 - val_loss: 0.4941 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.8850 - loss: 0.4784 - val_accuracy: 0.8547 - val_loss: 0.4702 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8949 - loss: 0.4620 - val_accuracy: 0.8709 - val_loss: 0.4570 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9174 - loss: 0.4083 - val_accuracy: 0.8604 - val_loss: 0.4562 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9133 - loss: 0.4268 - val_accuracy: 0.8620 - val_loss: 0.4611 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9208 - loss: 0.3927 - val_accuracy: 0.8515 - val_loss: 0.4807 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9316 - loss: 0.3856 - val_accuracy: 0.8819 - val_loss: 0.4371 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9264 - loss: 0.3947 - val_accuracy: 0.8505 - val_loss: 0.5058 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9366 - loss: 0.3651 - val_accuracy: 0.8719 - val_loss: 0.4531 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m238/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9477 - loss: 0.3244\n",
            "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - accuracy: 0.9477 - loss: 0.3244 - val_accuracy: 0.8756 - val_loss: 0.4528 - learning_rate: 5.0000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9388 - loss: 0.3433 - val_accuracy: 0.8772 - val_loss: 0.4514 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9506 - loss: 0.3159 - val_accuracy: 0.8709 - val_loss: 0.4676 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9488 - loss: 0.3120\n",
            "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9488 - loss: 0.3120 - val_accuracy: 0.8709 - val_loss: 0.4625 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9545 - loss: 0.3008 - val_accuracy: 0.8813 - val_loss: 0.4478 - learning_rate: 1.2500e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9554 - loss: 0.3048 - val_accuracy: 0.8813 - val_loss: 0.4477 - learning_rate: 1.2500e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9555 - loss: 0.2906\n",
            "Epoch 40: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9554 - loss: 0.2906 - val_accuracy: 0.8777 - val_loss: 0.4556 - learning_rate: 1.2500e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9651 - loss: 0.2596 - val_accuracy: 0.8824 - val_loss: 0.4494 - learning_rate: 6.2500e-05\n",
            "Epoch 42/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9634 - loss: 0.2582 - val_accuracy: 0.8829 - val_loss: 0.4535 - learning_rate: 6.2500e-05\n",
            "Epoch 43/50\n",
            "\u001b[1m239/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9657 - loss: 0.2564\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 19ms/step - accuracy: 0.9657 - loss: 0.2564 - val_accuracy: 0.8845 - val_loss: 0.4521 - learning_rate: 6.2500e-05\n",
            "Epoch 44/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9612 - loss: 0.2612 - val_accuracy: 0.8813 - val_loss: 0.4566 - learning_rate: 3.1250e-05\n",
            "Epoch 45/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - accuracy: 0.9661 - loss: 0.2543 - val_accuracy: 0.8808 - val_loss: 0.4559 - learning_rate: 3.1250e-05\n",
            "Epoch 46/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9667 - loss: 0.2465\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - accuracy: 0.9667 - loss: 0.2465 - val_accuracy: 0.8834 - val_loss: 0.4524 - learning_rate: 3.1250e-05\n",
            "Epoch 47/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9614 - loss: 0.2616 - val_accuracy: 0.8840 - val_loss: 0.4509 - learning_rate: 1.5625e-05\n",
            "Epoch 48/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.9582 - loss: 0.2640 - val_accuracy: 0.8845 - val_loss: 0.4527 - learning_rate: 1.5625e-05\n",
            "Epoch 49/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9673 - loss: 0.2480\n",
            "Epoch 49: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9673 - loss: 0.2481 - val_accuracy: 0.8761 - val_loss: 0.4673 - learning_rate: 1.5625e-05\n",
            "Epoch 50/50\n",
            "\u001b[1m240/240\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9629 - loss: 0.2525 - val_accuracy: 0.8845 - val_loss: 0.4548 - learning_rate: 1.0000e-05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved as 'trained_model.h5'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def fill_nan_with_statistic(df, stat_type='mean'):\n",
        "    if stat_type not in ['mean', 'median']:\n",
        "        raise ValueError(\"stat_type must be either 'mean' or 'median'\")\n",
        "\n",
        "    numeric_df = df.select_dtypes(include=[np.number])\n",
        "    fill_values = numeric_df.mean() if stat_type == 'mean' else numeric_df.median()\n",
        "    filled_df = df.copy()\n",
        "    filled_df[numeric_df.columns] = filled_df[numeric_df.columns].fillna(fill_values)\n",
        "\n",
        "    return filled_df\n",
        "\n",
        "data_path = '/content/cumulative.csv'\n",
        "data = pd.read_csv(data_path)\n",
        "data = data.drop(columns=['kepler_name', 'koi_tce_delivname', 'koi_teq_err1', 'koi_teq_err2'])\n",
        "data = fill_nan_with_statistic(data, stat_type='median')\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "data['koi_disposition'] = label_encoder.fit_transform(data['koi_disposition'])\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "y_encoded = one_hot_encoder.fit_transform(data[['koi_disposition']])\n",
        "\n",
        "X = data.drop(columns=['koi_disposition'])\n",
        "non_numeric_cols = X.select_dtypes(include=['object']).columns\n",
        "X = pd.get_dummies(X, columns=non_numeric_cols, drop_first=True)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(16, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(y_encoded.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5, verbose=1)\n",
        "\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[reduce_lr]\n",
        ")\n",
        "\n",
        "def preprocess_input_data(input_df):\n",
        "    input_df = fill_nan_with_statistic(input_df, stat_type='median')\n",
        "    input_df = input_df.drop(columns=['kepler_name', 'koi_tce_delivname', 'koi_teq_err1', 'koi_teq_err2'], errors='ignore')\n",
        "    input_df = pd.get_dummies(input_df, columns=non_numeric_cols, drop_first=True)\n",
        "    input_df = input_df.reindex(columns=X.columns, fill_value=0)\n",
        "    input_df = scaler.transform(input_df)\n",
        "    return input_df\n",
        "\n",
        "def evaluate_model(input_df=None):\n",
        "    if input_df is not None:\n",
        "        X_eval = preprocess_input_data(input_df)\n",
        "        y_eval = None\n",
        "    else:\n",
        "        X_eval = X_test\n",
        "        y_eval = y_test\n",
        "\n",
        "    y_pred_prob = model.predict(X_eval)\n",
        "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "    if y_eval is not None:\n",
        "        y_true = np.argmax(y_eval, axis=1)\n",
        "        test_accuracy = np.mean(y_true == y_pred)\n",
        "        f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "        print(f\"F1 Score: {f1:.4f}\")\n",
        "    else:\n",
        "        print(\"No true labels provided. Displaying predicted probabilities:\")\n",
        "\n",
        "    class_labels = label_encoder.inverse_transform(np.arange(len(one_hot_encoder.categories_[0])))  # Get original labels\n",
        "    for i in range(len(y_pred)):\n",
        "        predicted_class_index = y_pred[i]\n",
        "        predicted_probability = y_pred_prob[i][predicted_class_index]\n",
        "\n",
        "        print(f\"{predicted_probability * 100:.2f}% Class {predicted_class_index}: {class_labels[predicted_class_index]}\")\n",
        "\n",
        "\n",
        "model.save('trained_model.h5')\n",
        "print(\"Model saved as 'trained_model.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7A3eOGEqttqV",
        "outputId": "c77f00aa-fcfe-479a-cb41-956c5439b296"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    rowid     kepid kepoi_name koi_pdisposition  koi_score  koi_fpflag_nt  \\\n",
            "0       1  10797460  K00752.01        CANDIDATE      1.000              0   \n",
            "1       2  10797460  K00752.02        CANDIDATE      0.969              0   \n",
            "2       3  10811496  K00753.01   FALSE POSITIVE      0.000              0   \n",
            "3       4  10848459  K00754.01   FALSE POSITIVE      0.000              0   \n",
            "4       5  10854555  K00755.01        CANDIDATE      1.000              0   \n",
            "5       6  10872983  K00756.01        CANDIDATE      1.000              0   \n",
            "6       7  10872983  K00756.02        CANDIDATE      1.000              0   \n",
            "7       8  10872983  K00756.03        CANDIDATE      0.992              0   \n",
            "8       9   6721123  K00114.01   FALSE POSITIVE      0.000              0   \n",
            "9      10  10910878  K00757.01        CANDIDATE      1.000              0   \n",
            "10     11  11446443  K00001.01        CANDIDATE      0.811              0   \n",
            "11     12  10666592  K00002.01        CANDIDATE      1.000              0   \n",
            "12     13   6922244  K00010.01        CANDIDATE      0.998              0   \n",
            "13     14  10984090  K00112.02        CANDIDATE      1.000              0   \n",
            "14     15  10419211  K00742.01   FALSE POSITIVE      0.000              0   \n",
            "\n",
            "    koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  koi_period  ...  \\\n",
            "0               0              0              0    9.488036  ...   \n",
            "1               0              0              0   54.418383  ...   \n",
            "2               1              0              0   19.899140  ...   \n",
            "3               1              0              0    1.736952  ...   \n",
            "4               0              0              0    2.525592  ...   \n",
            "5               0              0              0   11.094321  ...   \n",
            "6               0              0              0    4.134435  ...   \n",
            "7               0              0              0    2.566589  ...   \n",
            "8               1              1              0    7.361790  ...   \n",
            "9               0              0              0   16.068647  ...   \n",
            "10              0              0              0    2.470613  ...   \n",
            "11              1              0              0    2.204735  ...   \n",
            "12              0              0              0    3.522498  ...   \n",
            "13              0              0              0    3.709214  ...   \n",
            "14              1              0              0   11.521446  ...   \n",
            "\n",
            "    koi_steff_err2  koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  \\\n",
            "0            -81.0      4.467           0.064          -0.096     0.927   \n",
            "1            -81.0      4.467           0.064          -0.096     0.927   \n",
            "2           -176.0      4.544           0.044          -0.176     0.868   \n",
            "3           -174.0      4.564           0.053          -0.168     0.791   \n",
            "4           -211.0      4.438           0.070          -0.210     1.046   \n",
            "5           -232.0      4.486           0.054          -0.229     0.972   \n",
            "6           -232.0      4.486           0.054          -0.229     0.972   \n",
            "7           -232.0      4.486           0.054          -0.229     0.972   \n",
            "8           -124.0      3.986           0.182          -0.098     1.958   \n",
            "9            -83.0      4.485           0.083          -0.028     0.848   \n",
            "10           -78.0      4.457           0.024          -0.024     0.964   \n",
            "11           -89.0      4.019           0.033          -0.027     1.952   \n",
            "12          -137.0      4.169           0.055          -0.045     1.451   \n",
            "13          -117.0      4.407           0.085          -0.114     1.022   \n",
            "14          -172.0      4.554           0.033          -0.176     0.848   \n",
            "\n",
            "    koi_srad_err1  koi_srad_err2         ra        dec  koi_kepmag  \n",
            "0           0.105         -0.061  291.93423  48.141651      15.347  \n",
            "1           0.105         -0.061  291.93423  48.141651      15.347  \n",
            "2           0.233         -0.078  297.00482  48.134129      15.436  \n",
            "3           0.201         -0.067  285.53461  48.285210      15.597  \n",
            "4           0.334         -0.133  288.75488  48.226200      15.509  \n",
            "5           0.315         -0.105  296.28613  48.224670      15.714  \n",
            "6           0.315         -0.105  296.28613  48.224670      15.714  \n",
            "7           0.315         -0.105  296.28613  48.224670      15.714  \n",
            "8           0.322         -0.483  298.86435  42.151569      12.660  \n",
            "9           0.033         -0.072  286.99948  48.375790      15.841  \n",
            "10          0.038         -0.038  286.80847  49.316399      11.338  \n",
            "11          0.099         -0.110  292.24728  47.969521      10.463  \n",
            "12          0.110         -0.110  281.28812  42.451080      13.563  \n",
            "13          0.143         -0.107  295.64871  48.495560      12.772  \n",
            "14          0.224         -0.075  297.07993  47.597401      15.472  \n",
            "\n",
            "[15 rows x 45 columns]\n"
          ]
        }
      ],
      "source": [
        "sample_input_df = pd.read_csv('/content/sample_input.csv')\n",
        "print(sample_input_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npUd3qc0NRwT",
        "outputId": "80c47164-30c2-40b7-f060-354e8ac29d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step\n",
            "No true labels provided. Displaying predicted probabilities:\n",
            "97.74% Class 1: CONFIRMED\n",
            "99.90% Class 1: CONFIRMED\n",
            "99.90% Class 2: FALSE POSITIVE\n",
            "99.85% Class 2: FALSE POSITIVE\n",
            "99.31% Class 1: CONFIRMED\n",
            "99.93% Class 1: CONFIRMED\n",
            "99.81% Class 1: CONFIRMED\n",
            "99.90% Class 1: CONFIRMED\n",
            "99.90% Class 2: FALSE POSITIVE\n",
            "99.79% Class 1: CONFIRMED\n",
            "97.61% Class 1: CONFIRMED\n",
            "99.93% Class 1: CONFIRMED\n",
            "95.61% Class 1: CONFIRMED\n",
            "99.83% Class 1: CONFIRMED\n",
            "99.86% Class 2: FALSE POSITIVE\n"
          ]
        }
      ],
      "source": [
        "evaluate_model(sample_input_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx6t2pIYwNKf",
        "outputId": "21f3bdb7-97e1-4453-ba6e-377800422cdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1250/1250 - 10s - 8ms/step - accuracy: 0.7906 - loss: 0.7454 - val_accuracy: 0.9780 - val_loss: 0.7557 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9618 - loss: 0.3064 - val_accuracy: 0.9849 - val_loss: 0.5374 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "1250/1250 - 6s - 5ms/step - accuracy: 0.9762 - loss: 0.2106 - val_accuracy: 0.9855 - val_loss: 0.3745 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "1250/1250 - 9s - 7ms/step - accuracy: 0.9792 - loss: 0.1638 - val_accuracy: 0.9877 - val_loss: 0.2343 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "1250/1250 - 6s - 5ms/step - accuracy: 0.9810 - loss: 0.1399 - val_accuracy: 0.9876 - val_loss: 0.2358 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "1250/1250 - 9s - 7ms/step - accuracy: 0.9814 - loss: 0.1232 - val_accuracy: 0.9872 - val_loss: 0.2264 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9822 - loss: 0.1225 - val_accuracy: 0.9877 - val_loss: 0.1416 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9822 - loss: 0.1189 - val_accuracy: 0.9880 - val_loss: 0.1836 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9830 - loss: 0.1150 - val_accuracy: 0.9881 - val_loss: 0.2125 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9830 - loss: 0.1164 - val_accuracy: 0.9884 - val_loss: 0.1373 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9831 - loss: 0.1133 - val_accuracy: 0.9879 - val_loss: 0.1430 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "1250/1250 - 7s - 5ms/step - accuracy: 0.9825 - loss: 0.1137 - val_accuracy: 0.9880 - val_loss: 0.2306 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "1250/1250 - 9s - 7ms/step - accuracy: 0.9830 - loss: 0.1144 - val_accuracy: 0.9875 - val_loss: 0.1705 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "1250/1250 - 7s - 5ms/step - accuracy: 0.9847 - loss: 0.1032 - val_accuracy: 0.9883 - val_loss: 0.2252 - learning_rate: 5.0000e-04\n",
            "Epoch 15/50\n",
            "1250/1250 - 9s - 7ms/step - accuracy: 0.9852 - loss: 0.0991 - val_accuracy: 0.9884 - val_loss: 0.2091 - learning_rate: 5.0000e-04\n",
            "Epoch 16/50\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9850 - loss: 0.0992 - val_accuracy: 0.9890 - val_loss: 0.2061 - learning_rate: 5.0000e-04\n",
            "Epoch 17/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9852 - loss: 0.0945 - val_accuracy: 0.9888 - val_loss: 0.1739 - learning_rate: 2.5000e-04\n",
            "Epoch 18/50\n",
            "1250/1250 - 7s - 5ms/step - accuracy: 0.9862 - loss: 0.0929 - val_accuracy: 0.9886 - val_loss: 0.1732 - learning_rate: 2.5000e-04\n",
            "Epoch 19/50\n",
            "\n",
            "Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9858 - loss: 0.0916 - val_accuracy: 0.9890 - val_loss: 0.2010 - learning_rate: 2.5000e-04\n",
            "Epoch 20/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9865 - loss: 0.0872 - val_accuracy: 0.9890 - val_loss: 0.2144 - learning_rate: 1.2500e-04\n",
            "Epoch 21/50\n",
            "1250/1250 - 6s - 5ms/step - accuracy: 0.9864 - loss: 0.0873 - val_accuracy: 0.9892 - val_loss: 0.1787 - learning_rate: 1.2500e-04\n",
            "Epoch 22/50\n",
            "\n",
            "Epoch 22: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9868 - loss: 0.0863 - val_accuracy: 0.9893 - val_loss: 0.1900 - learning_rate: 1.2500e-04\n",
            "Epoch 23/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9873 - loss: 0.0843 - val_accuracy: 0.9894 - val_loss: 0.1809 - learning_rate: 6.2500e-05\n",
            "Epoch 24/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9861 - loss: 0.0869 - val_accuracy: 0.9893 - val_loss: 0.1792 - learning_rate: 6.2500e-05\n",
            "Epoch 25/50\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9869 - loss: 0.0836 - val_accuracy: 0.9894 - val_loss: 0.1772 - learning_rate: 6.2500e-05\n",
            "Epoch 26/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9868 - loss: 0.0835 - val_accuracy: 0.9894 - val_loss: 0.1706 - learning_rate: 3.1250e-05\n",
            "Epoch 27/50\n",
            "1250/1250 - 7s - 5ms/step - accuracy: 0.9868 - loss: 0.0835 - val_accuracy: 0.9895 - val_loss: 0.1747 - learning_rate: 3.1250e-05\n",
            "Epoch 28/50\n",
            "\n",
            "Epoch 28: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9867 - loss: 0.0844 - val_accuracy: 0.9894 - val_loss: 0.1779 - learning_rate: 3.1250e-05\n",
            "Epoch 29/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9876 - loss: 0.0812 - val_accuracy: 0.9894 - val_loss: 0.1772 - learning_rate: 1.5625e-05\n",
            "Epoch 30/50\n",
            "1250/1250 - 6s - 4ms/step - accuracy: 0.9873 - loss: 0.0822 - val_accuracy: 0.9894 - val_loss: 0.1762 - learning_rate: 1.5625e-05\n",
            "Epoch 31/50\n",
            "\n",
            "Epoch 31: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9873 - loss: 0.0821 - val_accuracy: 0.9895 - val_loss: 0.1799 - learning_rate: 1.5625e-05\n",
            "Epoch 32/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9871 - loss: 0.0828 - val_accuracy: 0.9893 - val_loss: 0.1816 - learning_rate: 1.0000e-05\n",
            "Epoch 33/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9870 - loss: 0.0815 - val_accuracy: 0.9895 - val_loss: 0.1786 - learning_rate: 1.0000e-05\n",
            "Epoch 34/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9872 - loss: 0.0828 - val_accuracy: 0.9895 - val_loss: 0.1785 - learning_rate: 1.0000e-05\n",
            "Epoch 35/50\n",
            "1250/1250 - 6s - 5ms/step - accuracy: 0.9868 - loss: 0.0817 - val_accuracy: 0.9894 - val_loss: 0.1800 - learning_rate: 1.0000e-05\n",
            "Epoch 36/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9873 - loss: 0.0812 - val_accuracy: 0.9896 - val_loss: 0.1803 - learning_rate: 1.0000e-05\n",
            "Epoch 37/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9873 - loss: 0.0813 - val_accuracy: 0.9894 - val_loss: 0.1824 - learning_rate: 1.0000e-05\n",
            "Epoch 38/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9871 - loss: 0.0823 - val_accuracy: 0.9894 - val_loss: 0.1766 - learning_rate: 1.0000e-05\n",
            "Epoch 39/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9875 - loss: 0.0805 - val_accuracy: 0.9895 - val_loss: 0.1748 - learning_rate: 1.0000e-05\n",
            "Epoch 40/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9873 - loss: 0.0804 - val_accuracy: 0.9894 - val_loss: 0.1717 - learning_rate: 1.0000e-05\n",
            "Epoch 41/50\n",
            "1250/1250 - 5s - 4ms/step - accuracy: 0.9874 - loss: 0.0802 - val_accuracy: 0.9894 - val_loss: 0.1755 - learning_rate: 1.0000e-05\n",
            "Epoch 42/50\n",
            "1250/1250 - 9s - 7ms/step - accuracy: 0.9875 - loss: 0.0822 - val_accuracy: 0.9895 - val_loss: 0.1757 - learning_rate: 1.0000e-05\n",
            "Epoch 43/50\n",
            "1250/1250 - 6s - 5ms/step - accuracy: 0.9876 - loss: 0.0800 - val_accuracy: 0.9895 - val_loss: 0.1744 - learning_rate: 1.0000e-05\n",
            "Epoch 44/50\n",
            "1250/1250 - 8s - 7ms/step - accuracy: 0.9877 - loss: 0.0792 - val_accuracy: 0.9896 - val_loss: 0.1752 - learning_rate: 1.0000e-05\n",
            "Epoch 45/50\n",
            "1250/1250 - 7s - 5ms/step - accuracy: 0.9873 - loss: 0.0799 - val_accuracy: 0.9894 - val_loss: 0.1735 - learning_rate: 1.0000e-05\n",
            "Epoch 46/50\n",
            "1250/1250 - 8s - 7ms/step - accuracy: 0.9874 - loss: 0.0820 - val_accuracy: 0.9896 - val_loss: 0.1759 - learning_rate: 1.0000e-05\n",
            "Epoch 47/50\n",
            "1250/1250 - 6s - 4ms/step - accuracy: 0.9877 - loss: 0.0785 - val_accuracy: 0.9896 - val_loss: 0.1758 - learning_rate: 1.0000e-05\n",
            "Epoch 48/50\n",
            "1250/1250 - 9s - 7ms/step - accuracy: 0.9870 - loss: 0.0831 - val_accuracy: 0.9895 - val_loss: 0.1751 - learning_rate: 1.0000e-05\n",
            "Epoch 49/50\n",
            "1250/1250 - 6s - 5ms/step - accuracy: 0.9873 - loss: 0.0801 - val_accuracy: 0.9896 - val_loss: 0.1743 - learning_rate: 1.0000e-05\n",
            "Epoch 50/50\n",
            "1250/1250 - 4s - 3ms/step - accuracy: 0.9877 - loss: 0.0795 - val_accuracy: 0.9896 - val_loss: 0.1741 - learning_rate: 1.0000e-05\n",
            "Test accuracy: 98.96%\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1 Score: 0.99\n",
            "Model saved as 'trained_model_Galaxy_classification.h5'\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Load and preprocess dataset\n",
        "data_path = '/content/SDSS_DR18.csv'  # Replace with your actual file path\n",
        "data = pd.read_csv(data_path)\n",
        "\n",
        "# Drop rows with missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "data['class'] = label_encoder.fit_transform(data['class'])\n",
        "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
        "y_encoded = one_hot_encoder.fit_transform(data[['class']])\n",
        "\n",
        "# Separate features and target variable\n",
        "X = data.drop(columns=['class', 'objid', 'specobjid', 'run'])  # Exclude non-feature columns\n",
        "non_numeric_cols = X.select_dtypes(include=['object']).columns\n",
        "X = pd.get_dummies(X, columns=non_numeric_cols, drop_first=True)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build the ANN model with 5 hidden layers\n",
        "model = Sequential([\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(16, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(y_encoded.shape[1], activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callback for learning rate reduction\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-5, verbose=1)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[reduce_lr],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Predict the classes for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate F1 score\n",
        "f1 = f1_score(y_true_classes, y_pred_classes, average='weighted')\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "model.save('trained_model_Galaxy_classification.h5')\n",
        "print(\"Model saved as 'trained_model_Galaxy_classification.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UWuoz3VHwOJE",
        "outputId": "53d15487-118e-4f76-8c77-16355ccddcdf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 212ms/step\n",
            "Predictions for the first 5 rows:\n",
            "['STAR' 'STAR' 'STAR' 'STAR' 'STAR']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "sample_input_df = pd.read_csv('/content/sample_input.csv')\n",
        "\n",
        "\n",
        "sample_input_df = sample_input_df.drop(columns=['class', 'objid', 'specobjid', 'run'], errors='ignore')\n",
        "\n",
        "non_numeric_cols = sample_input_df.select_dtypes(include=['object']).columns\n",
        "sample_input_df = pd.get_dummies(sample_input_df, columns=non_numeric_cols, drop_first=True)\n",
        "\n",
        "\n",
        "X_train_columns = X.columns\n",
        "\n",
        "missing_cols = set(X_train_columns) - set(sample_input_df.columns)\n",
        "for col in missing_cols:\n",
        "    sample_input_df[col] = 0\n",
        "extra_cols = set(sample_input_df.columns) - set(X_train_columns)\n",
        "sample_input_df = sample_input_df.drop(columns=extra_cols, errors='ignore')\n",
        "sample_input_df = sample_input_df[X_train_columns]\n",
        "\n",
        "sample_input_df = scaler.transform(sample_input_df)\n",
        "\n",
        "\n",
        "sample_predictions = model.predict(sample_input_df)\n",
        "sample_pred_classes = np.argmax(sample_predictions, axis=1)\n",
        "predicted_classes = label_encoder.inverse_transform(sample_pred_classes)\n",
        "\n",
        "sample_input_df = pd.DataFrame(sample_input_df, columns=X_train_columns)\n",
        "sample_input_df['predicted_class'] = predicted_classes\n",
        "\n",
        "\n",
        "sample_input_df.to_csv('predicted_classes_output.csv', index=False)\n",
        "print(\"Predictions for the first 5 rows:\")\n",
        "print(predicted_classes[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkwaguNgwRim"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}